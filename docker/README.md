# ğŸ³ Docker Setup - Containerize Your AI Dreams!

> **Get this app running in containers faster than you can say "Docker compose up"!**

## ğŸš€ Quick Start (Zero to Hero)

**Want to run everything in containers?** We got you covered!

```bash
# Development setup (the easy way)
docker-compose up -d

# With Ollama for local AI models (the cool way)  
docker-compose -f docker-compose.ollama.yml up -d

# Production ready (the pro way)
docker-compose -f docker-compose.prod.yml up -d
```

**That's it!** ğŸ‰ Your app is now running in containers!

## ğŸ“ What's In Here?

```
ğŸ³ docker/
â”œâ”€â”€ ğŸ³ docker-compose.yml         # Main development setup
â”œâ”€â”€ ğŸ¤– docker-compose.ollama.yml  # With local AI models
â”œâ”€â”€ ğŸ­ docker-compose.prod.yml    # Production configuration
â”œâ”€â”€ ğŸ“‹ Dockerfile                 # Main app container
â”œâ”€â”€ ğŸ”§ Dockerfile.ollama          # Ollama container setup
â””â”€â”€ ğŸ“– README.md                  # You are here!
```

## ğŸ› ï¸ Configuration Options

### ğŸ”§ Development Setup

**Perfect for local development:**

```yaml
# Basic setup with hot reload
services:
  app:
    build: .
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=development
    volumes:
      - .:/app
      - /app/node_modules
```

### ğŸ¤– With Ollama (Local AI Models)

**Want to run AI models locally?** This setup includes Ollama for privacy and speed:

```bash
# Start everything including Ollama
docker-compose -f docker-compose.ollama.yml up -d

# Pull some models
docker exec -it ollama ollama pull llama2
docker exec -it ollama ollama pull codellama
```

### ğŸ­ Production Ready

**Going live?** Use the production configuration:

```bash
# Production deployment
docker-compose -f docker-compose.prod.yml up -d
```

## ğŸ”§ Environment Variables

**Set these up in your `.env` file:**

```bash
# Essential stuff
NEXT_PUBLIC_SUPABASE_URL=your_supabase_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_anon_key
SUPABASE_SERVICE_ROLE=your_service_role

# AI API Keys (get the good stuff)
OPENAI_API_KEY=sk-your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key
GOOGLE_GENERATIVE_AI_API_KEY=your_gemini_key

# For Ollama setup
OLLAMA_BASE_URL=http://ollama:11434
```

## ğŸ¯ Common Commands

```bash
# Start everything
docker-compose up -d

# View logs (see what's happening)
docker-compose logs -f

# Stop everything
docker-compose down

# Rebuild and restart (when you change something)
docker-compose up --build -d

# Check what's running
docker-compose ps

# Access the app container
docker-compose exec app bash

# Clean up everything (nuclear option)
docker-compose down -v --rmi all
```

## ğŸ› Troubleshooting

**Something not working?** Here are the most common fixes:

### ğŸ”„ Port Already in Use
```bash
# Find what's using port 3000
lsof -i :3000

# Or use a different port
docker-compose up -d --env PORT=3001
```

### ğŸ“ Volume Issues
```bash
# Reset volumes
docker-compose down -v
docker-compose up -d
```

### ğŸ”§ Build Problems
```bash
# Clean rebuild
docker-compose down
docker-compose build --no-cache
docker-compose up -d
```

### ğŸ¤– Ollama Not Working
```bash
# Check Ollama status
docker-compose exec ollama ollama list

# Restart Ollama service
docker-compose restart ollama
```

## ğŸš€ Performance Tips

**Make it faster:**

1. **Use Build Cache** - Don't rebuild unnecessarily
2. **Volume Mounts** - For development, mount source code
3. **Multi-stage Builds** - Smaller production images
4. **Health Checks** - Monitor container health
5. **Resource Limits** - Set memory and CPU limits

## ğŸ” Security Best Practices

**Keep it secure:**

- ğŸ”’ Never commit `.env` files
- ğŸ›¡ï¸ Use secrets for production
- ğŸš« Don't run as root in containers
- ğŸ” Scan images for vulnerabilities
- ğŸšª Limit exposed ports

## ğŸŒ Deployment Options

### â˜ï¸ Cloud Platforms

**Deploy anywhere:**

- **Vercel** - `vercel deploy`
- **Netlify** - Connect GitHub repo
- **Railway** - One-click deploy
- **DigitalOcean** - App Platform
- **AWS** - ECS or App Runner
- **Google Cloud** - Cloud Run

### ğŸ  Self-Hosted

**Run on your own server:**

```bash
# On your server
git clone https://github.com/mohameodo/agentai
cd agentai/docker
cp .env.example .env
# Edit .env with your values
docker-compose -f docker-compose.prod.yml up -d
```

## ğŸ“Š Monitoring

**Keep an eye on things:**

```bash
# Resource usage
docker stats

# Container health
docker-compose ps

# Application logs
docker-compose logs app

# Database logs  
docker-compose logs db
```

## ğŸ¤ Need Help?

**We're here for you:**

- ğŸ› **Bug Reports:** [GitHub Issues](https://github.com/mohameodo/agentai/issues)
- ğŸ’¬ **Questions:** [Discussions](https://github.com/mohameodo/agentai/discussions)
- ğŸ“– **Documentation:** [Main Docs](../docs/)
- ğŸŒŸ **Feature Requests:** [Feature Template](https://github.com/mohameodo/agentai/issues/new?template=feature_request.md)

---

**Happy containerizing! ğŸ³âœ¨**

*Made with ğŸ’œ by developers who actually use Docker*
